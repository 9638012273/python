{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install --upgrade pip\n",
    "%pip install html5lib\n",
    "%pip install beautifulsoup4\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Scraper_&_Bot  #\n",
    "#=================#\n",
    "\n",
    "# link:-\n",
    "#https://docs.google.com/document/d/1dTK7_Cz8IF3AwtcJI64P5DPkiV6GPUWoh0jJFncADqc/edit?tab=t.0\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"      *  WELCOME TO SCRAPER AND BOT \\n         A Web Scraping and Automation Utility\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "while True:     #LOOP CONTINUE WHILW TRUE\n",
    "\n",
    "    print(\"===============================================\")\n",
    "    print(\"  ***   Chose an option:\")\n",
    "    print(\"===============================================\")\n",
    "    print(\"   1. Web Scraoing\")\n",
    "    print(\"   2. Web Automation\")                        #OPSTIONS\n",
    "    print(\"   3. Combined Tasks (Scraping + Automation)\")\n",
    "    print(\"   4. Exit\")\n",
    "    print(\"===============================================\\n\")\n",
    "\n",
    "    main_choise=int(input(\"Enter your choise:\"))  \n",
    "\n",
    "    match main_choise:\n",
    "        case 1:\n",
    "            while True:\n",
    "                print(\"  ***   Web Scraping Operations:\")\n",
    "                print(\"   1. Scrape Blog data(Titles and Links)\")\n",
    "                print(\"   2. Scrape E-commerce products(name, price ,erating)\")\n",
    "                print(\"   3. Scrape Weathre data\")           \n",
    "                print(\"   4. Back To Main Menu\\n\")\n",
    "\n",
    "                File_choise=int(input(\"Enter Your Choise:\"))\n",
    "\n",
    "                match File_choise:\n",
    "                    case 1:\n",
    "                        Title=[]\n",
    "                        Link=[]\n",
    "\n",
    "                        print(\"WEBSITE:- https://www.octoparse.com/blog\")\n",
    "\n",
    "                        url=\"https://www.octoparse.com/blog\"\n",
    "                        re=requests.get(url)\n",
    "                        soup=BeautifulSoup(re.text,\"html.parser\")\n",
    "\n",
    "                        title=soup.find_all(\"div\",class_=\"posts_card__aP9rp\")\n",
    "                        for i in title:\n",
    "                            tt=i.h2.text\n",
    "                            Title.append(tt)\n",
    "\n",
    "                        print(\"Find All Titles:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        for i in Title:\n",
    "                            print(i)\n",
    "\n",
    "                        links=soup.find_all(\"h2\",class_=\"title\")\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Links for Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        n_url=\"https://www.octoparse.com\"\n",
    "                        for i in links:\n",
    "                            li=n_url+i.a['href']\n",
    "                            Link.append(li)\n",
    "\n",
    "                        for i in Link:\n",
    "                            print(i)\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Title\":Title,\"Links\":Link})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"programm will be continue...\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    case 2:\n",
    "\n",
    "                        product_name=[]\n",
    "                        prices=[]\n",
    "                        description=[]\n",
    "                        reviews=[]\n",
    "\n",
    "                        url=\"https://www.flipkart.com/search?q=mobile&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY&page=\"\n",
    "                        r=requests.get(url)\n",
    "                        soup=BeautifulSoup(r.text,\"html.parser\")\n",
    "                        box=soup.find(\"div\",class_=\"DOjaWF gdgoEp\")\n",
    "                        \n",
    "                        print(\"link:-https://www.flipkart.com\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Name:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        names=box.find_all(\"div\",class_=\"KzDlHZ\")\n",
    "                        for i in names:\n",
    "                            name=i.text\n",
    "                            product_name.append(name)\n",
    "\n",
    "                        for i in product_name:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Price:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        price=box.find_all(\"div\",class_=\"Nx9bqj _4b5DiR\")\n",
    "                        for i in price:\n",
    "                            prc=i.text\n",
    "                            prices.append(prc)\n",
    "\n",
    "                        for i in prices:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Description:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        deccript=box.find_all(\"ul\",class_=\"G4BRas\")\n",
    "                        for i in deccript:\n",
    "                            dec=i.text\n",
    "                            description.append(dec)\n",
    "\n",
    "                        for i in description:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Review:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        review=box.find_all(\"div\",class_=\"XQDdHH\")\n",
    "                        for i in review:\n",
    "                            rev=i.text\n",
    "                            reviews.append(rev)\n",
    "\n",
    "                        for i in reviews:\n",
    "                            print(i)\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Name\":product_name,\"Price\":prices,\"Description\":description,\"Review\":reviews})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"programm will be continue...\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "                            \n",
    "\n",
    "                    case 3:\n",
    "                        Weather=[]\n",
    "                        Day=[]\n",
    "\n",
    "                        url=\"https://weather.com/en-GB/weather/tenday/l/Surat+Gujarat+India?canonicalCityId=75ef1280a5b3c404918862c0d70da9dd41dfa23eece46ce89b8d26e7b8f389e7\"\n",
    "\n",
    "                        request=requests.get(url)\n",
    "                        soup=BeautifulSoup(request.text,\"html.parser\")\n",
    "\n",
    "                        print(\"link:-https://weather.com\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find weather days:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        day=soup.find_all(\"h2\",class_=\"DetailsSummary--daypartName--CcVUz\")\n",
    "                        for datas in day:\n",
    "                            day_data=datas.text\n",
    "                            Day.append(day_data)\n",
    "\n",
    "                        for i in Day:\n",
    "                            print(i)\n",
    "                            \n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find weather data:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        weather=soup.find_all(\"span\",class_=\"DetailsSummary--highTempValue--VHKaO\")\n",
    "                        for data in weather:\n",
    "                            wth=data.text\n",
    "                            Weather.append(wth)\n",
    "\n",
    "                        for i in Weather:\n",
    "                            print(i)\n",
    "\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Date/Day\":Day,\"Tempreture\":Weather})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"programm will be continue...\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    case 4:\n",
    "                        break\n",
    "\n",
    "        case 4:\n",
    "            print(\"Exiting programm...\")\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIT_PYTHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
