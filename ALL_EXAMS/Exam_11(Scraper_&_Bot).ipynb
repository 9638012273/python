{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install --upgrade pip\n",
    "%pip install html5lib\n",
    "%pip install beautifulsoup4\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Scraper_&_Bot  #\n",
    "#=================#\n",
    "\n",
    "# link:-\n",
    "#https://docs.google.com/document/d/1dTK7_Cz8IF3AwtcJI64P5DPkiV6GPUWoh0jJFncADqc/edit?tab=t.0\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By                       # import libraries\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"      *  WELCOME TO SCRAPER AND BOT \\n         A Web Scraping and Automation Utility\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "while True:     \n",
    "\n",
    "    print(\"===============================================\")\n",
    "    print(\"  ***   Chose an option:\")\n",
    "    print(\"===============================================\")\n",
    "    print(\"   1. Web Scraping\")\n",
    "    print(\"   2. Web Automation\")                        #OPSTIONS\n",
    "    print(\"   3. Combined Tasks (Scraping + Automation)\")\n",
    "    print(\"   4. Exit\")\n",
    "    print(\"===============================================\\n\")\n",
    "\n",
    "    main_choise=int(input(\"Enter your choise:\"))  \n",
    "    match main_choise:\n",
    "#________________________________________________________________________________________________________________________________#\n",
    "#                                    CASE 1 --->  Web Scraping\n",
    "#________________________________________________________________________________________________________________________________#\n",
    "        case 1:\n",
    "            while True:\n",
    "                print(\"  ***   Web Scraping Operations:\")\n",
    "                print(\"   1. Scrape Blog data(Titles and Links)\")\n",
    "                print(\"   2. Scrape E-commerce products(name, price ,description ,rating)\")\n",
    "                print(\"   3. Scrape Weather data\")           \n",
    "                print(\"   4. Back To Main Menu\\n\")\n",
    "\n",
    "                File_choise=int(input(\"Enter Your Choise:\"))\n",
    "                match File_choise:\n",
    "\n",
    "                    #<-----------Scrape Title and Link from Blog Data------------------------------------------------------------>\n",
    "                    case 1:\n",
    "                        Title=[]\n",
    "                        Link=[]\n",
    "\n",
    "                        print(\"WEBSITE:- https://www.octoparse.com/blog\")\n",
    "                        url=\"https://www.octoparse.com/blog\"\n",
    "                        re=requests.get(url)\n",
    "                        soup=BeautifulSoup(re.text,\"html.parser\")\n",
    "\n",
    "                        title=soup.find_all(\"div\",class_=\"posts_card__aP9rp\")\n",
    "                        for i in title:\n",
    "                            tt=i.h2.text\n",
    "                            Title.append(tt)\n",
    "\n",
    "                        print(\"Find All Titles:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        for i in Title:\n",
    "                            print(i)\n",
    "\n",
    "                        links=soup.find_all(\"h2\",class_=\"title\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Links for Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "\n",
    "                        n_url=\"https://www.octoparse.com\"\n",
    "                        for i in links:\n",
    "                            li=n_url+i.a['href']\n",
    "                            Link.append(li)\n",
    "                        for i in Link:\n",
    "                            print(i)\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Title\":Title,\"Links\":Link})\n",
    "                            dataframe.to_csv(filename)\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    #<-------------Scrape Product Details From Flipcart---------------------------------------------------------->\n",
    "                    case 2:\n",
    "\n",
    "                        product_name=[]\n",
    "                        prices=[]\n",
    "                        description=[]\n",
    "                        reviews=[]\n",
    "\n",
    "                        url=\"https://www.flipkart.com/search?q=mobile&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&as-pos=1&as-type=HISTORY&page=\"\n",
    "                        r=requests.get(url)\n",
    "                        soup=BeautifulSoup(r.text,\"html.parser\")\n",
    "                        box=soup.find(\"div\",class_=\"DOjaWF gdgoEp\")\n",
    "                        \n",
    "                        print(\"link:-https://www.flipkart.com\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Name:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        names=box.find_all(\"div\",class_=\"KzDlHZ\")\n",
    "                        for i in names:\n",
    "                            name=i.text\n",
    "                            product_name.append(name)\n",
    "                        for i in product_name:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Price:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        price=box.find_all(\"div\",class_=\"Nx9bqj _4b5DiR\")\n",
    "                        for i in price:\n",
    "                            prc=i.text\n",
    "                            prices.append(prc)\n",
    "                        for i in prices:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Description:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        deccript=box.find_all(\"ul\",class_=\"G4BRas\")\n",
    "                        for i in deccript:\n",
    "                            dec=i.text\n",
    "                            description.append(dec)\n",
    "                        for i in description:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Review:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        review=box.find_all(\"div\",class_=\"XQDdHH\")\n",
    "                        for i in review:\n",
    "                            rev=i.text\n",
    "                            reviews.append(rev)\n",
    "                        for i in reviews:\n",
    "                            print(i)\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Name\":product_name,\"Price\":prices,\"Description\":description,\"Review\":reviews})\n",
    "                            dataframe.to_csv(filename)\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "                            \n",
    "                    #<-------------------Scrape Live Weather Data---------------------------------------------------------------->\n",
    "                    case 3:\n",
    "                        Weather=[]\n",
    "                        Day=[]\n",
    "\n",
    "                        url=\"https://weather.com/en-GB/weather/tenday/l/Surat+Gujarat+India?canonicalCityId=75ef1280a5b3c404918862c0d70da9dd41dfa23eece46ce89b8d26e7b8f389e7\"\n",
    "                        request=requests.get(url)\n",
    "                        soup=BeautifulSoup(request.text,\"html.parser\")\n",
    "\n",
    "                        print(\"link:-https://weather.com\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find weather days:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        day=soup.find_all(\"h2\",class_=\"DetailsSummary--daypartName--CcVUz\")\n",
    "                        for datas in day:\n",
    "                            day_data=datas.text\n",
    "                            Day.append(day_data)\n",
    "                        for i in Day:\n",
    "                            print(i)\n",
    "                            \n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find weather data:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        weather=soup.find_all(\"span\",class_=\"DetailsSummary--highTempValue--VHKaO\")\n",
    "                        for data in weather:\n",
    "                            wth=data.text\n",
    "                            Weather.append(wth)\n",
    "                        for i in Weather:\n",
    "                            print(i)\n",
    "\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Date/Day\":Day,\"Tempreture\":Weather})\n",
    "                            dataframe.to_csv(filename)\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    #<----------------------------------------------------------------------------------------------------------->\n",
    "                    case 4:\n",
    "                        break\n",
    "                    case _:\n",
    "                        print(\"Invelid choise...\")\n",
    "        \n",
    "#________________________________________________________________________________________________________________________________#\n",
    "#                                    CASE 2 --->  Web Automation\n",
    "#________________________________________________________________________________________________________________________________#\n",
    "        case 2:\n",
    "            while True:\n",
    "                print(\"  ***   Web Automation Operations:\")\n",
    "                print(\"   1. Login to Website\")\n",
    "                print(\"   2. fill and submit a form\")\n",
    "                print(\"   3. search and capture wekipedia results\")           \n",
    "                print(\"   4. Back To Main Menu\\n\")\n",
    "\n",
    "                auto_choise=int(input(\"Enter Your Choise:\"))\n",
    "\n",
    "                match auto_choise:\n",
    "                    #<------------------Sign in Using Web Automation------------------------------------------------------------->\n",
    "                    case 1:\n",
    "                        \n",
    "                        try:\n",
    "\n",
    "                            mobile=input(\"Enter your Username:\")\n",
    "                            password=input(\"Enter your Mpin:\")\n",
    "\n",
    "                            service = Service(ChromeDriverManager().install())\n",
    "                            driver = webdriver.Chrome(service=service)\n",
    "                            driver.get(f\"https://student.rnwmultimedia.com/\")\n",
    "                            time.sleep(2)\n",
    "\n",
    "                            elem = driver.find_element(By.ID,\"mobile_no\").send_keys(mobile)\n",
    "                            time.sleep(2)\n",
    "                            elem = driver.find_element(By.ID,\"mpin\").send_keys(Keys.RETURN)\n",
    "                            time.sleep(2)\n",
    "                            elem = driver.find_element(By.ID,\"mpin\").send_keys(password)\n",
    "                            time.sleep(2)\n",
    "                            button=driver.find_element(By.CLASS_NAME,\"mobileEnter\")\n",
    "                            elem= button.find_element(By.XPATH, \"//button[@type='submit']\").send_keys(Keys.RETURN)\n",
    "                            time.sleep(4)\n",
    "\n",
    "                            driver.quit()\n",
    "                            print(\"\\n Login Successfully.....\\n\")\n",
    "\n",
    "                        except Exception:\n",
    "                            print(\"\\nError: Please enter velid data...\")\n",
    "\n",
    "                    #<----------------Form Fillup Using Web Automation----------------------------------------------------------->\n",
    "                    case 2:\n",
    "                        f_name=input(\"Enter Your First name:\")\n",
    "                        l_name=input(\"Enter Your Last name :\")\n",
    "                        email=input(\"Enter Your Email:\")\n",
    "                        mobile=input(\"Enter Your Mobile no.:\")\n",
    "                        city=input(\"Enter Your city:\")\n",
    "                        state=input(\"Enter Your state:\")\n",
    "                        country=input(\"Enter Your country:\")\n",
    "\n",
    "                        service = Service(ChromeDriverManager().install())\n",
    "                        driver = webdriver.Chrome(service=service)\n",
    "                        driver.get(f\"https://form.jotform.com/umaretiyamiit/simple-flat-contact-form\")\n",
    "                        time.sleep(2)\n",
    "\n",
    "\n",
    "                        elem = driver.find_element(By.ID,\"first_3\").send_keys(f_name)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"last_3\").send_keys(l_name)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"input_4\").send_keys(email)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"input_6_full\").send_keys(mobile)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"input_7_city\").send_keys(city)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"input_7_state\").send_keys(state)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"input_7_postal\").send_keys(country)\n",
    "                        time.sleep(2)\n",
    "                        button=driver.find_element(By.CLASS_NAME,\"form-input-wide\")\n",
    "                        elem= button.find_element(By.XPATH, \"//button[@type='submit']\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        driver.quit()\n",
    "                        print(\"\\n Form Fillup Successfully.....\\n\")\n",
    "\n",
    "                   #<-------------------Search Text and Find Data---------------------------------------------------------------->\n",
    "                    case 3:\n",
    "                        search=\"python tutorial\"\n",
    "\n",
    "                        service = Service(ChromeDriverManager().install())\n",
    "                        driver = webdriver.Chrome(service=service)\n",
    "                        driver.get(f\"https://www.wikipedia.org/\")\n",
    "                        time.sleep(2)\n",
    "\n",
    "\n",
    "                        elem = driver.find_element(By.ID,\"searchInput\")\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"searchInput\").send_keys(search)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"searchInput\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        Title=[]\n",
    "                        Link=[]\n",
    "                        url=\"https://en.wikipedia.org/wiki/Special:Search?go=Go&search=python+tutorial&ns0=1\"\n",
    "\n",
    "                        request=requests.get(url)\n",
    "                        # print(request.status_code)\n",
    "                        soup=BeautifulSoup(request.text,\"html.parser\")\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        title=soup.find_all(\"div\",class_=\"mw-search-result-heading\")\n",
    "                        for i in title:\n",
    "                            tt=i.text\n",
    "                            Title.append(tt)\n",
    "                        for i in Title:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Links for Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        links=soup.find_all(\"div\",class_=\"mw-search-result-heading\")\n",
    "                        for i in links:\n",
    "                            link=i.a['href'] \n",
    "                            final=url+link\n",
    "                            Link.append(final)\n",
    "                        for i in Link:\n",
    "                            print(i)\n",
    "\n",
    "                        driver.quit()\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Title\":Title,\"Link\":Link})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    #<----------------------------------------------------------------------------------------------------------->\n",
    "                    case 4:\n",
    "                        break\n",
    "\n",
    "                    case _:\n",
    "                        print(\"Invelid choise...\")\n",
    "            \n",
    "#________________________________________________________________________________________________________________________________#\n",
    "#                                    CASE 3 --->  Web Scraping  + Web Automation\n",
    "#________________________________________________________________________________________________________________________________#\n",
    "\n",
    "        case 3:\n",
    "            while True:\n",
    "                print(\"  ***   Combined task Operations:\")\n",
    "                print(\"   1. Scrape Search Results and Visit Links\")\n",
    "                print(\"   2. Scrape products from an E-commerce Website\")          \n",
    "                print(\"   3. Back To Main Menu\\n\")\n",
    "\n",
    "                auto_choise=int(input(\"Enter Your Choise:\"))\n",
    "\n",
    "                match auto_choise:\n",
    "\n",
    "                    #<-----------Go to amazon and Search thing And Take Screenshot----------------------------------------------->\n",
    "                    case 1:\n",
    "                        service = Service(ChromeDriverManager().install())\n",
    "                        driver = webdriver.Chrome(service=service)\n",
    "                        driver.get(f\"https://www.amazon.in/\")\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        elem = driver.find_element(By.ID,\"twotabsearchtextbox\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "                        search=\"Smart TV\"\n",
    "                        elem = driver.find_element(By.ID,\"twotabsearchtextbox\").send_keys(search)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.ID,\"twotabsearchtextbox\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        driver.save_screenshot('C://Users/HP/OneDrive/Pictures/Screenshots/screenshot_1.png')\n",
    "\n",
    "                        NAME=[]\n",
    "                        PRICE=[]\n",
    "\n",
    "                        url=\"https://www.amazon.in/s?k=Smart+TV&crid=2A82SD52DOELN&sprefix=smart+tv%2Caps%2C461&ref=nb_sb_noss_2\"\n",
    "                        request=requests.get(url)\n",
    "                        # print(request.status_code)\n",
    "                        soup=BeautifulSoup(request.text,\"html.parser\")\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        title=soup.find_all(\"h2\",class_=\"a-size-medium a-spacing-none a-color-base a-text-normal\")\n",
    "                        for i in title:\n",
    "                            tt=i.text\n",
    "                            NAME.append(tt)\n",
    "                        for i in NAME:\n",
    "                            print(i)\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Links for Title:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        links=soup.find_all(\"span\",class_=\"a-price-whole\")\n",
    "                        for i in links:\n",
    "                            link=i.text\n",
    "                            PRICE.append(link)\n",
    "                        for i in PRICE:\n",
    "                            print(i)\n",
    "\n",
    "                        driver.quit()\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Mobile_name\":NAME,\"Price\":PRICE})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "\n",
    "                    #<---------------Goto flipcart and Search Text and Take data Using Automation-------------------------------->\n",
    "                    case 2:\n",
    "                        service = Service(ChromeDriverManager().install())\n",
    "                        driver = webdriver.Chrome(service=service)\n",
    "                        driver.get(f\"https://www.flipkart.com/\")\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        elem = driver.find_element(By.CLASS_NAME,\"Pke_EE\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "                        search=\"Macbooks\"\n",
    "                        elem = driver.find_element(By.CLASS_NAME,\"Pke_EE\").send_keys(search)\n",
    "                        time.sleep(2)\n",
    "                        elem = driver.find_element(By.CLASS_NAME,\"Pke_EE\").send_keys(Keys.RETURN)\n",
    "                        time.sleep(2)\n",
    "\n",
    "                        path=os.path.join(os.getcwd(),\"screenshot_1.png\")       #take screenshot\n",
    "                        driver.save_screenshot(path)\n",
    "\n",
    "                        Product_names=[]\n",
    "                        Prices=[]\n",
    "\n",
    "                        url=\"https://www.flipkart.com/search?q=Macbooks&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "                        request=requests.get(url)\n",
    "                        # print(request.status_code)\n",
    "                        soup=BeautifulSoup(request.text,\"html.parser\")\n",
    "                        box=soup.find(\"div\",class_=\"DOjaWF gdgoEp\")\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Name:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "\n",
    "                        title=box.find_all(\"div\",class_=\"KzDlHZ\")\n",
    "                        for i in title:\n",
    "                            tt=i.text\n",
    "                            Product_names.append(tt)\n",
    "                        for i in Product_names:\n",
    "                            print(i)\n",
    "                        print(len(Product_names))\n",
    "\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        print(\"Find All Product Prices:-\")\n",
    "                        print(\"---------------------------------------------\")\n",
    "                        price=box.find_all(\"div\",class_=\"Nx9bqj _4b5DiR\")\n",
    "                        for i in price:\n",
    "                            prc=i.text\n",
    "                            Prices.append(prc)\n",
    "                        for i in Prices:\n",
    "                            print(i)\n",
    "                        print(len(Prices))\n",
    "\n",
    "                        driver.quit()\n",
    "                        print(\"\\nScreenshot Taken Successfully...\")\n",
    "\n",
    "                        makefile=input(\"Do You Want To save this data? (yes/no):\")\n",
    "                        if(makefile==\"yes\"):\n",
    "                            filename=input(\"Enyter File name to save (e.g., data.csv):\")\n",
    "                            dataframe=pd.DataFrame({\"Product_name\":Product_names,\"Prices\":Prices})\n",
    "                            dataframe.to_csv(filename)\n",
    "\n",
    "                            print(f\"\\n'{filename}' created successfully ...\\n\")\n",
    "\n",
    "                        elif(makefile==\"no\"):\n",
    "                            print(\"\\nprogramm will be continue...\\n\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Enter input only yes or no...\")\n",
    "                        \n",
    "                    #<----------------------------------------------------------------------------------------------------------->\n",
    "                    case 3:\n",
    "                        break\n",
    "                    case _:\n",
    "                        print(\"Invelid choise...\")\n",
    "\n",
    "        case 4:\n",
    "            print(\"Exiting programm...\")\n",
    "            break\n",
    "        case _:\n",
    "            print(\"Invelid choise...\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIT_PYTHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
